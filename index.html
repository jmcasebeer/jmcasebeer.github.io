<!DOCTYPE html>
<html>

<head>
    <title>Jonah Casebeer - Research Scientist</title>
    <meta name="description"
        content="Jonah Casebeer's personal website showcasing research, publications, and projects.">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="/style.css">
    <script src="/script.js"></script>
    <link rel="icon" href="/assets/dft.png" type="image/png">
</head>

<body>
    <div class="page">
        <div class="title-section">
            <h1>Jonah Casebeer</h1>
            <div class="institution">
                Adobe Research<br>
                San Francisco
            </div>
            <img src="/assets/prof_pic_2023.jpg" alt="Profile Picture of Jonah Casebeer" class="headshot">

            <div class="social-links">
                <a href="mailto:jonah.casebeer@ieee.org" aria-label="Email Jonah Casebeer">Email</a>
                <a href="https://scholar.google.com/citations?user=QwAo-K4AAAAJ&hl=en" target="_blank"
                    aria-label="Google Scholar Profile">Scholar</a>
                <a href="https://research.adobe.com/person/jonah-casebeer/" target="_blank"
                    aria-label="Adobe Research Profile">Adobe</a>
            </div>
        </div>

        <div class="abstract">
            <div class="abstract-title">About Me</div>
            <p>
                I am a research scientist in Adobe Research's <a href="https://research.adobe.com/research/audio/"
                    target="_blank">Audio</a> group. I'm broadly interested in generative
                models for generation, manipulation, and representation, with a particular focus on audio and video
                applications. I received my Ph.D. in Computer Science and B.S. in Statistics and Computer Science from
                the University of Illinois Urbana-Champaign, where I was advised by Prof. Paris Smaragdis.
            </p>
        </div>
        <div class="section">
            <h2>Prospective Interns</h2>
            <p>If you're passionate about machine learning, deep learning, or signal processing applied to audio, get in
                touch. Send your CV and a brief description of your research interests.</p>
        </div>
        <div class="section">
            <h2>Media Coverage</h2>
            <p>Some of my work has been integrated into Adobe's products. Here is a selection of coverage: <a
                    href="https://www.theverge.com/news/807809/adobe-firefly-ai-audio-generate-soundtrack-speech"
                    target="_blank">The Verge</a>, <a
                    href="https://www.cnet.com/tech/services-and-software/adobes-new-ai-is-all-about-audio-how-to-create-music-for-your-videos-with-firefly/"
                    target="_blank">CNET</a>, <a
                    href="https://www.wired.com/story/adobe-max-2025-firefly-photoshop-updates/"
                    target="_blank">WIRED</a>, <a
                    href="https://www.thewrap.com/adobe-max-ai-tools-youtube-shorts-creators/" target="_blank">The
                    Wrap</a>, <a
                    href="https://www.zdnet.com/article/adobe-firefly-can-generate-royalty-free-music-for-your-videos-in-seconds-now-heres-how/"
                    target="_blank">ZDNET</a>, <a
                    href="https://theaieconomy.substack.com/p/adobe-firefly-ai-soundtrack-speech-generation"
                    target="_blank">The AI Economy</a>, <a
                    href="https://au.news.yahoo.com/adobes-firefly-now-ai-generate-120018271.html"
                    target="_blank">Yahoo! News</a>, <a
                    href="https://www.nasdaq.com/press-release/adobe-expands-creative-possibility-ai-every-creator-adobe-max-2025-2025-10-28"
                    target="_blank">Nasdaq</a>, and <a
                    href="https://www.musicbusinessworldwide.com/adobes-new-firefly-can-create-custom-fully-licensed-ai-soundtracks-for-video/"
                    target="_blank">Music Business Worldwide</a>.</p>
        </div>
        <div class="section">
            <h2>Publications</h2>
            <div class="publication-year">2025</div>
            <div class="publication-item">
                <div class="publication-title">
                    DRAGON: Distributional Rewards Optimize Diffusion Generative Models
                </div>
                <div class="publication-details">
                    <p>Bai, Yatong and <strong>Casebeer, Jonah</strong> and Sojoudi, Somayeh and Bryan, Nicholas J
                    </p>
                    <p><em>Transactions on Machine Learning Research (TMLR)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2504.15217">[PDF]</a>
                        <a href="https://arxiv.org/abs/2504.15217">[arXiv]</a>
                        <a href="https://ml-dragon.github.io/web">[Demo]</a>
                    </div>
                </div>
            </div>
            <div class="publication-item">
                <div class="publication-title">
                    Re-Bottleneck: Latent Re-Structuring for Neural Audio Autoencoders
                </div>
                <div class="publication-details">
                    <p>Bralios, Dimitrios and <strong>Casebeer, Jonah</strong> and Smaragdis, Paris</p>
                    <p><em>IEEE International Workshop on Machine Learning for Signal Processing (MLSP)</em></p>
                    <p>Best Paper Award</p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2507.07867">[PDF]</a>
                        <a href="https://arxiv.org/abs/2507.07867">[arXiv]</a>
                        <a href="https://github.com/dbralios/rebottleneck">[Code]</a>
                    </div>
                </div>
            </div>
            <div class="publication-item">
                <div class="publication-title">
                    Learning to Upsample and Upmix Audio in the Latent Domain
                </div>
                <div class="publication-details">
                    <p>Bralios, Dimitrios and Smaragdis, Paris and <strong>Casebeer, Jonah</strong>
                    </p>
                    <p><em>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2506.00681">[PDF]</a>
                        <a href="https://arxiv.org/abs/2506.00681">[arXiv]</a>
                        <a href="https://re-encoders.github.io/latent-bwe-m2s/">[Demo]</a>
                    </div>
                </div>
            </div>
            <div class="publication-item">
                <div class="publication-title">
                    Presto! Distilling Steps and Layers for Accelerating Music Generation
                </div>
                <div class="publication-details">
                    <p>Novack, Zachary and Zhu, Ge and <strong>Casebeer, Jonah</strong> and McAuley, Julian and
                        Berg-Kirkpatrick, Taylor and Bryan, Nicholas J</p>
                    <p><em>International Conference of Learning Representations (ICLR)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2410.05167">[PDF]</a>
                        <a href="https://arxiv.org/abs/2410.05167">[arXiv]</a>
                        <a href="https://presto-music.github.io/web/">[Demo]</a>
                    </div>
                </div>
            </div>
            <div class="publication-item">
                <div class="publication-title">
                    REGEN: Learning Compact Video Embedding with (Re-) Generative Decoder
                </div>
                <div class="publication-details">
                    <p>Zhang, Yitian and Mai, Long and Mahapatra, Aniruddha and Bourgin, David and Hong, Yicong and
                        <strong>Casebeer, Jonah</strong> and Liu, Feng and Fu, Yun
                    </p>
                    <p><em>International Conference on Computer Vision (ICCV)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2503.08665">[PDF]</a>
                        <a href="https://arxiv.org/abs/2503.08665">[arXiv]</a>
                        <a href="https://bespontaneous.github.io/REGEN/">[Demo]</a>
                    </div>
                </div>
            </div>
            <div class="publication-year">2024</div>
            <div class="publication-item">
                <div class="publication-title">
                    Scaling Up Adaptive Filter Optimizers
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Bryan, Nicholas J and Smaragdis, Paris</p>
                    <p><em>Preprint</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2403.00977">[PDF]</a>
                        <a href="https://arxiv.org/abs/2403.00977">[arXiv]</a>
                        <a href="https://github.com/adobe-research/MetaAF">[Code]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Meta-AF Echo Cancellation for Improved Keyword Spotting
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Wu, Junkai and Smaragdis, Paris</p>
                    <p><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2312.10605">[PDF]</a>
                        <a href="https://arxiv.org/abs/2312.10605">[arXiv]</a>
                        <a href="https://github.com/adobe-research/MetaAF/tree/ct-meta-af/zoo/ct_af">[Code]</a>
                    </div>
                </div>
            </div>

            <div class="publication-year">2023</div>
            <div class="publication-item">
                <div class="publication-title">
                    Meta-Learning for Adaptive Filtering — Ph.D. Thesis
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong></p>
                    <p><em>Ph.D. Thesis, University of Illinois at Urbana-Champaign</em></p>
                    <div class="publication-links">
                        <a href="https://www.ideals.illinois.edu/items/129160">[Website]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Meta-AF: Meta-Learning for Adaptive Filters
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Bryan, Nicholas J. and Smaragdis, Paris</p>
                    <p><em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2204.11942">[PDF]</a>
                        <a href="https://arxiv.org/abs/2204.11942">[arXiv]</a>
                        <a href="https://github.com/adobe-research/MetaAF">[Code]</a>
                    </div>
                </div>
            </div>

            <div class="publication-year">2022</div>
            <div class="publication-item">
                <div class="publication-title">
                    Meta-Learning for Adaptive Filters with Higher-Order Frequency Dependencies
                </div>
                <div class="publication-details">
                    <p>Wu, Junkai and <strong>Casebeer, Jonah</strong> and Bryan, Nicholas J. and Smaragdis, Paris</p>
                    <p><em>IEEE International Workshop on Acoustic Signal Enhancement (IWAENC)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2209.09955">[PDF]</a>
                        <a href="https://arxiv.org/abs/2209.09955">[arXiv]</a>
                        <a href="https://github.com/adobe-research/MetaAF">[Code]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    NICE-Beam: Neural Integrated Covariance Estimators for Time-Varying Beamformers
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Donley, Jacob and Wong, Daniel and Xu, Buye and Kumar,
                        Anurag
                    </p>
                    <p><em>Preprint</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2112.04613">[PDF]</a>
                        <a href="https://arxiv.org/abs/2112.04613">[arXiv]</a>
                    </div>
                </div>
            </div>

            <div class="publication-year">2021</div>
            <div class="publication-item">
                <div class="publication-title">
                    Auto-DSP: Learning to Optimize Acoustic Echo Cancellers
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Bryan, Nicholas J and Smaragdis, Paris</p>
                    <p><em>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2110.04284">[PDF]</a>
                        <a href="https://arxiv.org/abs/2110.04284">[arXiv]</a>
                        <a href="https://github.com/jmcasebeer/autodsp">[Code]</a>
                        <!-- <a href="https://jmcasebeer.github.io/projects/auto-dsp/">[Demo]</a> -->
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Sound Event Detection with Adaptive Frequency Selection
                </div>
                <div class="publication-details">
                    <p>Wang, Zhepei and <strong>Casebeer, Jonah</strong> and Clemmitt, Adam and Tzinis, Efthymios and
                        Smaragdis, Paris</p>
                    <p><em>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2105.07596">[PDF]</a>
                        <a href="https://arxiv.org/abs/2105.07596">[arXiv]</a>
                        <a href="https://github.com/zhepeiw/adaptive_freq_select">[Code]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Separate but Together: Unsupervised Federated Learning for Speech Enhancement from Non-IID Data
                </div>
                <div class="publication-details">
                    <p>Tzinis, Efthymios and <strong>Casebeer, Jonah</strong> and Wang, Zhepei and Smaragdis, Paris</p>
                    <p><em>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2105.04727">[PDF]</a>
                        <a href="https://arxiv.org/abs/2105.04727">[arXiv]</a>
                        <a href="https://github.com/etzinis/fedenhance">[Code]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Enhancing Into the Codec: Noise Robust Speech Coding with Vector-Quantized Autoencoders
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Vale, Vinjai and Isik, Umut and Valin, Jean-Marc and Giri,
                        Ritwik and Krishnaswamy, Arvindh</p>
                    <p><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2102.06610">[PDF]</a>
                        <a href="https://arxiv.org/abs/2102.06610">[arXiv]</a>
                    </div>
                </div>
            </div>

            <div class="publication-year">2020</div>
            <div class="publication-item">
                <div class="publication-title">
                    Communication-Cost Aware Microphone Selection for Neural Speech Enhancement with Ad-Hoc Microphone
                    Arrays
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Kaikaus, Jamshed and Smaragdis, Paris</p>
                    <p><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2011.07348">[PDF]</a>
                        <a href="https://arxiv.org/abs/2011.07348">[arXiv]</a>
                        <a href="https://github.com/jmcasebeer/cost_aware_enhancement">[Code]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Efficient Trainable Front-Ends for Neural Speech Enhancement
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Isik, Umut and Venkataramani, Shrikant and Krishnaswamy,
                        Arvindh
                    </p>
                    <p><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2002.09286">[PDF]</a>
                        <a href="https://arxiv.org/abs/2002.09286">[arXiv]</a>
                    </div>
                </div>
            </div>

            <div class="publication-year">2019</div>
            <div class="publication-item">
                <div class="publication-title">
                    Deep Tensor Factorization for Spatially-Aware Scene Decomposition
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Colomb, Michael and Smaragdis, Paris</p>
                    <p><em>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/1905.01391">[PDF]</a>
                        <a href="https://arxiv.org/abs/1905.01391">[arXiv]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Dimensional Analysis of Laughter in Female Conversational Speech
                </div>
                <div class="publication-details">
                    <p>Pietrowicz, Mary and Agurto, Carla and <strong>Casebeer, Jonah</strong> and Hasegawa-Johnson,
                        Mark
                        and Karahalios, Karrie and Cecchi, Guillermo</p>
                    <p><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></p>
                    <div class="publication-links">
                        <a href="https://www.ibm.com/blogs/research/2019/05/conversational-laughter-ai/">[Website]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Multipath-Enabled Private Audio with Noise
                </div>
                <div class="publication-details">
                    <p>Chaman, Anadi and Liu, Yu-Jeh and <strong>Casebeer, Jonah</strong> and Dokmanić, Ivan</p>
                    <p><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/1811.07065">[PDF]</a>
                        <a href="https://arxiv.org/abs/1811.07065">[arXiv]</a>
                        <a href="https://github.com/achaman2/noise-becomes-voice">[Code]</a>
                        <a href="https://swing-research.github.io/private-audio/">[Demo]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Multi-View Networks For Multi-Channel Audio Classification
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Wang, Zhepei and Smaragdis, Paris</p>
                    <p><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/1811.01251">[PDF]</a>
                        <a href="https://arxiv.org/abs/1811.01251">[arXiv]</a>
                        <a href="http://zhepeiw.com/2019/05/24/blog2.html">[Demo]</a>
                    </div>
                </div>
            </div>

            <div class="publication-year">2018</div>
            <div class="publication-item">
                <div class="publication-title">
                    Cocktails, but No Party: Multipath-Enabled Private Audio
                </div>
                <div class="publication-details">
                    <p>Liu, Yu-Jeh and <strong>Casebeer, Jonah</strong> and Dokmanić, Ivan</p>
                    <p><em>IEEE International Workshop on Acoustic Signal Enhancement (IWAENC)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/1809.05862">[PDF]</a>
                        <a href="https://arxiv.org/abs/1809.05862">[arXiv]</a>
                        <a href="https://github.com/swing-research/sonicdot">[Code]</a>
                        <a href="https://swing-research.github.io/sonicdot/">[Demo]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Verbal Protest Recognition in Children with Autism
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Sarker, Hillol and Dhuliawala, Murtaza and Fay, Nicholas and
                        Pietrowicz, Mary and
                        Das, Amar
                    </p>
                    <p><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></p>
                    <div class="publication-links">
                        <a href="https://ieeexplore.ieee.org/document/8462514">[PDF]</a>
                        <a
                            href="https://sigport.org/sites/default/files/docs/icassp2018_verbal_protest_poster.final__0.pdf">[Poster]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    Multi-View Networks for Denoising of Arbitrary Numbers of Channels
                </div>
                <div class="publication-details">
                    <p><strong>Casebeer, Jonah</strong> and Luc, Brian and Smaragdis, Paris</p>
                    <p><em>IEEE International Workshop on Acoustic Signal Enhancement (IWAENC)</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/1806.05296">[PDF]</a>
                        <a href="https://arxiv.org/abs/1806.05296">[arXiv]</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">
                    End-to-End Source Separation with Adaptive Front-Ends
                </div>
                <div class="publication-details">
                    <p>Venkataramani, Shrikant and <strong>Casebeer, Jonah</strong> and Smaragdis, Paris</p>
                    <p><em>Asilomar Conference on Signals, Systems and Computers</em></p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/1705.02514">[PDF]</a>
                        <a href="https://arxiv.org/abs/1705.02514">[arXiv]</a>
                    </div>
                </div>
            </div>

            <div class="publication-year">2017</div>
            <div class="publication-item">
                <div class="publication-title">
                    Adaptive Front-Ends for End-to-End Source Separation
                </div>
                <div class="publication-details">
                    <p>Venkataramani, Shrikant and <strong>Casebeer, Jonah</strong> and Smaragdis, Paris</p>
                    <p><em>NeurIPS ML4Audio Workshop</em></p>
                    <div class="publication-links">
                        <a href="https://paris.cs.illinois.edu/pubs/shrikant-nips2017.pdf">[PDF]</a>
                    </div>
                </div>
            </div>

        </div>

        <div class="footnote">
            Last updated: Jan 2026
        </div>
    </div>
</body>

</html>